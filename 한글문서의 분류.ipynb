{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한글 문서의 분류\n",
    "다음무비(http://movie.daum.net)로부터 crawl한 영화리뷰를 이용하여 분류 연습<br>\n",
    "영화리뷰와 영화의 제목을 학습해서 주어진 리뷰내용으로 어떤 영화에 대한 리뷰인지를 예측하고자 함\n",
    "### data file 내용\n",
    "'신과함께', '코코', '라라랜드', '인피니티 워', '곤지암' 다섯개의 영화에 대해 총 1827개의 리뷰를 수집\n",
    "csv 파일 안에 리뷰내용, 평점, 영화이름 의 순으로 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:38:56.700480Z",
     "start_time": "2020-11-08T08:38:56.665873Z"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "text = []\n",
    "y = []\n",
    "with open('movie_data.csv', encoding='CP949') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row: #그 줄에 내용이 있는 경우에만\n",
    "            text.append(row[0]) #영화 리뷰를 text 리스트에 추가\n",
    "            y.append(row[2]) #영화이름을 text 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:39:04.253279Z",
     "start_time": "2020-11-08T08:39:04.239987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 1827\n",
      "Movie titles of reivews: {'곤지암', '라라랜드', '인피니티 워', '코코', '신과함께'}\n"
     ]
    }
   ],
   "source": [
    "print('Num of samples: {}'.format(len(text))) # 전체 리뷰 갯수 확인\n",
    "print('Movie titles of reivews: {}'.format(set(y))) # 리뷰할 영화명 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:39:10.976847Z",
     "start_time": "2020-11-08T08:39:09.884641Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split #\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, random_state=0)\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:44:47.140398Z",
     "start_time": "2020-11-08T08:44:47.116320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) #1827의 0.75 # 트레인 데이터가 75%로 구성되었음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:45:19.194919Z",
     "start_time": "2020-11-08T08:45:18.158591Z"
    }
   },
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import\n",
    "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
    "twitter_tag = Okt()\n",
    "#twitter_tag = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:45:29.934995Z",
     "start_time": "2020-11-08T08:45:25.063335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1])) #둘째 리뷰에 대해 형태소 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:45:48.116441Z",
     "start_time": "2020-11-08T08:45:48.063827Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['혹시', '역시', '편집', '사운드', '공포', '영화', '푸시', '인상', '여기', '또']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_tag.nouns(X_train[1]) #둘째 리뷰에서 명사만 추출 --> 유의미한 것만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:48:54.956661Z",
     "start_time": "2020-11-08T08:48:54.937149Z"
    }
   },
   "outputs": [],
   "source": [
    "# 본격적으로 text 변수에 저장된 영화 리뷰를 형태소 분석기에 넣어 명사의 갯수를 count\n",
    "def twit_tokenizer(text): # Twitter 형태소 분석기의 명사추출함수를 tokenizer 함수로 사용\n",
    "    return twitter_tag.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:49:07.557009Z",
     "start_time": "2020-11-08T08:49:02.619627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8364963503649635\n",
      "Test score 0.6717724288840262\n",
      "(1370, 1156)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer # TF-IDF 기능을 사용\n",
    "from sklearn.linear_model import LogisticRegression # 로지스틱회귀분석 임포트\n",
    "\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=2) #Twitter 형태소분석기에서 명사만 추출하는 함수를 tokenizer로 이용\n",
    "# twit_tokenizer 대신 twitter_tag.nouns를 직접 써도 됨\n",
    "# 하나의 문서에서만 출현한 단어는 쓸모가 없으므로 제외, 즉 최소 document frequency를 2로 설정\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector\n",
    "X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector\n",
    "\n",
    "clf = LogisticRegression() # logistic regression 분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # 분류기 학습시키기\n",
    "print('Train score', clf.score(X_train_tfidf, y_train)) # train data 예측정확도\n",
    "print('Test score', clf.score(X_test_tfidf, y_test)) # test data 예측정확도\n",
    "print(X_train_tfidf.shape) # 총 1156개의 명사로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:54:38.353482Z",
     "start_time": "2020-11-08T08:54:38.339428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['졸잼 최고',\n",
       " '내용, 음악 , 연기력  무엇하나 빠지는것이 없네요 특히 음악은 계속 찾아 듣게되요^^',\n",
       " '아맥2D로 느즈막히 관람.... 히어로가 많이나오지만, 이걸 꽤나 잘 버무려놓음. 뻔한스토리의 틀을 벗어나려 노력한점은 높은점수를 줄만함.... 블럭버스터액션, 영상미는 말이필요없음...... 후속편 기대됨!',\n",
       " '후반부터 쫄렸다.',\n",
       " '진짜. 솔직히 한국 공포영화중에 이렇게 소재별로인건 정말 오랜만인듯; 지들끼리 소리지르고 정신없이 우왕자왕 심지어 무섭지도않어 효과음만크고 진짜최악임ㅉㅉ',\n",
       " '소문난 잔치에 먹을거 없음..ㅜㅜ',\n",
       " 'good!',\n",
       " '아 점수를 줄 수가 없네  화면은 왜그리도 흔들어 데는지........ 재미도 없고 가볍기만하고 .... 최악의 재미없는 배멀미 영화',\n",
       " '영화 보면서 펑펑물었네요~ 부모님 사랑에 대해 다시한번 생각하게 했던 영화네요^ ^',\n",
       " '슬픈 스토리지만 삶을 돌아보게 하는 영화다. 죄를 지은자는 그 벌을 고스란히 받으리라. 사회 각종범죄자들 뉘우치길 바란다.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10] #test data에서 앞 10개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:55:01.259333Z",
     "start_time": "2020-11-08T08:55:01.232700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워',\n",
       "       '신과함께', '코코', '신과함께'], dtype='<U6')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test_tfidf[:10]) # test data의 앞 10개에 대한 예측내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:55:42.419777Z",
     "start_time": "2020-11-08T08:55:42.414776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워', '곤지암', '신과함께', '신과함께']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10]) # test data 앞 10개의 실제 영화제목 --> 즉, 영화리뷰 내용을 보고 이 영화의 제목이 뭔지를 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 성능을 개선하기 위한 노력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:56:33.833430Z",
     "start_time": "2020-11-08T08:56:33.822338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "# morphs()는 명사 외에도 모든 형태소를 포함, 왜냐면 명사만 가지고 하니까 정확도가 떨어지는 문제 발생\n",
    "print(twitter_tag.morphs(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T08:56:59.485673Z",
     "start_time": "2020-11-08T08:56:55.445354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.897080291970803\n",
      "Test score 0.6520787746170679\n",
      "(1370, 2259)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twitter_tag.morphs, min_df=2) # 명사 대신 모든 형태소를 사용\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#명사만 사용한 것에 비해 train score는 상승, test score는 하락"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:01:48.757745Z",
     "start_time": "2020-11-08T09:01:48.717173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('혹시', 'Noun'), ('나', 'Josa'), ('하다', 'Verb'), ('보다', 'Verb'), ('역시', 'Noun'), ('나다', 'Verb'), (';;', 'Punctuation'), ('편집', 'Noun'), ('과', 'Josa'), ('사운드', 'Noun'), ('로', 'Josa'), ('주다', 'Verb'), ('작다', 'Adjective'), ('공포', 'Noun'), ('영화', 'Noun'), (\"'\", 'Punctuation'), ('푸시', 'Noun'), (\"'\", 'Punctuation'), ('에서', 'Josa'), ('인상', 'Noun'), ('깊다', 'Adjective'), ('보다', 'Verb'), ('여기', 'Noun'), ('서', 'Josa'), ('또', 'Noun'), ('보다', 'Verb'), (';;', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.pos(X_train[1], norm=True, stem=True)) #pos()는 형태소와 품사를 함께 제공 --> 품사를 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:02:41.590966Z",
     "start_time": "2020-11-08T09:02:41.580453Z"
    }
   },
   "outputs": [],
   "source": [
    "def twit_tokenizer2(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사만을 사용하는 함수를 생성한다.\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "#            result.append('/'.join([word, tag]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:02:47.024231Z",
     "start_time": "2020-11-08T09:02:47.006172Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '하다', '보다', '역시', '나다', '편집', '사운드', '주다', '작다', '공포', '영화', '푸시', '인상', '깊다', '보다', '여기', '또', '보다']\n"
     ]
    }
   ],
   "source": [
    "print(twit_tokenizer2(X_train[1])) # 사용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:03:38.127344Z",
     "start_time": "2020-11-08T09:03:31.502315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8715328467153285\n",
      "Test score 0.6849015317286652\n",
      "(1370, 1584)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, min_df=2) #명사, 동사, 형용사를 이용하여(위에서 정의한 함수 이용) tfidf 생성\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "# 현재까지 중에서 test score가 가장 뛰어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:16:01.866595Z",
     "start_time": "2020-11-08T09:16:01.849533Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모든 형태소를 다 사용하고 품사를 알 수 있도록 하면? 품사 구분 안하고 다 써본 걸로 정확도 판별해보자.\n",
    "def twit_tokenizer3(text):\n",
    "    #target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:16:14.134449Z",
     "start_time": "2020-11-08T09:16:07.053153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8934306569343066\n",
      "Test score 0.6805251641137856\n",
      "(1370, 2022)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer3, min_df=2)\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#성능이 오히려 떨어지고 품사 표시 없이 전체를 다 사용한 경우에 비해 train은 떨어지고, test는 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:16:28.849125Z",
     "start_time": "2020-11-08T09:16:28.794817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.945\n",
      "Test set score: 0.678\n"
     ]
    }
   ],
   "source": [
    "# train score가 높으므로 ridge를 쓰면 어떨까?\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(alpha = 1)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "# train score가 올라가는 현상이 벌어짐\n",
    "# test score가 올라갔으나 명사, 형용사, 동사를 쓴 것보다 떨어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:16:51.585759Z",
     "start_time": "2020-11-08T09:16:51.541178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.718\n",
      "Test set score: 0.641\n",
      "Used features count: 240 out of 2022\n"
     ]
    }
   ],
   "source": [
    "#lasso를 쓰면?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:17:13.162291Z",
     "start_time": "2020-11-08T09:17:12.817966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01097394 0.01404418 0.01144555 0.01099639 0.00916745 0.00875989\n",
      " 0.00835936 0.00794889 0.00777951 0.00738573 0.00715576 0.00666331\n",
      " 0.00659225 0.00618775 0.00592882 0.00582323 0.0056259  0.00542605\n",
      " 0.00525103 0.00523123 0.00520221 0.00506956 0.00494388 0.00479853\n",
      " 0.00469988 0.00459151 0.00458951 0.00452605 0.00436703 0.00430513\n",
      " 0.00425153 0.00416082 0.00409785 0.00402263 0.00399375 0.00395814\n",
      " 0.00392284 0.00387447 0.00373225 0.0037107  0.00365221 0.00363015\n",
      " 0.00358802 0.00353893 0.0035093  0.00346765 0.00340709 0.00336875\n",
      " 0.00333267 0.00330703 0.00323153 0.00321719 0.00315377 0.0031451\n",
      " 0.00309437 0.00308121 0.00306176 0.00301699 0.00299564 0.0029579\n",
      " 0.00293779 0.00290843 0.00288642 0.00288784 0.00286235 0.00283992\n",
      " 0.00279693 0.00276647 0.00274554 0.00271376 0.00268972 0.00266628\n",
      " 0.00264023 0.0026273  0.00261976 0.00258926 0.00260291 0.00256814\n",
      " 0.00255141 0.00253006 0.0025199  0.00251091 0.00249142 0.0024794\n",
      " 0.00245132 0.00243894 0.00241102 0.00239672 0.00238019 0.00237122\n",
      " 0.00235986 0.00232467 0.00231871 0.002283   0.00226055 0.00225036\n",
      " 0.00223037 0.00222612 0.00219787 0.00218921 0.00218064 0.00216516\n",
      " 0.00213901 0.00213778 0.0021136  0.00210876 0.0020832  0.00207942\n",
      " 0.00206797 0.00204236 0.00203479 0.0020269  0.00201987 0.00200722\n",
      " 0.00199754 0.00197912 0.00197709 0.00196681 0.00195594 0.00194742\n",
      " 0.00194117 0.00192401 0.00191051 0.00190203 0.00189982 0.00189731\n",
      " 0.00186826 0.00186939 0.00185025 0.00184861 0.00183904 0.0018199\n",
      " 0.00181261 0.00180328 0.00179611 0.00178676 0.00178316 0.00177893\n",
      " 0.00176848 0.00176515 0.00173992 0.0017368  0.00173118 0.0017249\n",
      " 0.00172031 0.00170531 0.00169438 0.00168882 0.00168238 0.00167123\n",
      " 0.00166227 0.00165972 0.00164826 0.00163723 0.00162954 0.00162381\n",
      " 0.00161781 0.00161202 0.00160222 0.00160021 0.00158998 0.00158488\n",
      " 0.00158276 0.0015596  0.00155644 0.00155235 0.00154224 0.00153983\n",
      " 0.00153027 0.0015205  0.00151545 0.00151279 0.00150846 0.00150121\n",
      " 0.00149211 0.00149111 0.00148111 0.00147769 0.00146451 0.00146087\n",
      " 0.00145562 0.0014482  0.00144266 0.00143159 0.00142836 0.00142448\n",
      " 0.0014177  0.0014149  0.00141131 0.00140123 0.00139798 0.00138953\n",
      " 0.00138572 0.00138543 0.00137329 0.00136592 0.00136173 0.00135699\n",
      " 0.00135148 0.00134263 0.0013397  0.00133093 0.00132462 0.0013218\n",
      " 0.00131496 0.00131177 0.00130871 0.00130723 0.00129597 0.00129146\n",
      " 0.00128061 0.00127529 0.00127001 0.00126542 0.00126179 0.00125436\n",
      " 0.00125104 0.00124489 0.00123999 0.00123498 0.00122767 0.00122438\n",
      " 0.00121473 0.00120846 0.00120487 0.00119461 0.00119086 0.00118559\n",
      " 0.00117697 0.00117593 0.00116459 0.0011625  0.00115425 0.0011516\n",
      " 0.00114033 0.00113612 0.00113303 0.00112548 0.00111781]\n",
      "0.6285939859146402\n",
      "[7.19101469 4.37868531 3.87981898 3.804571   3.46996373 3.39199124\n",
      " 3.31373981 3.23100999 3.19786937 3.11533759 3.07111007 2.97767979\n",
      " 2.94269568 2.85139275 2.79059406 2.76552206 2.71890893 2.6695944\n",
      " 2.6305617  2.62199702 2.61466233 2.5820506  2.5481985  2.51039835\n",
      " 2.48445135 2.46511231 2.45547067 2.4414871  2.39486692 2.37785563\n",
      " 2.36333018 2.33764968 2.31989102 2.29889927 2.29024451 2.28017422\n",
      " 2.26978586 2.25815241 2.21402552 2.20779465 2.19013993 2.18353222\n",
      " 2.17175302 2.15589033 2.14793029 2.13590973 2.1157117  2.1037017\n",
      " 2.09212717 2.08535927 2.06122422 2.05680347 2.04145981 2.03271567\n",
      " 2.01681521 2.0117875  2.00525575 1.99096136 1.98454319 1.97132511\n",
      " 1.96493819 1.95698635 1.94989134 1.94748381 1.93948074 1.93307885\n",
      " 1.91667463 1.9061096  1.898942   1.88797907 1.87974376 1.87149866\n",
      " 1.86267545 1.85768572 1.85515859 1.84942353 1.84892463 1.83651446\n",
      " 1.83096007 1.82295879 1.81920058 1.81680862 1.80923171 1.80485095\n",
      " 1.79426377 1.79028048 1.77959534 1.77416371 1.76820157 1.76478816\n",
      " 1.76047961 1.74735229 1.74618917 1.73165054 1.72315203 1.71913884\n",
      " 1.71149186 1.70991864 1.69907528 1.69564395 1.69236816 1.68708792\n",
      " 1.67705401 1.6756991  1.66625445 1.66417991 1.65442025 1.65270638\n",
      " 1.64813154 1.63871292 1.63539859 1.6315617  1.62916882 1.62455713\n",
      " 1.61976734 1.61240026 1.61138688 1.60751635 1.60274437 1.59928049\n",
      " 1.59697799 1.58980118 1.58482461 1.58053513 1.57966691 1.5785793\n",
      " 1.56808921 1.56689675 1.55921292 1.55829337 1.55422068 1.54648453\n",
      " 1.5430275  1.53908168 1.5358605  1.53188848 1.53038792 1.52916343\n",
      " 1.52399824 1.52258185 1.51209805 1.51053368 1.508151   1.50528382\n",
      " 1.50342417 1.49656914 1.49172892 1.48939768 1.4867743  1.48173009\n",
      " 1.4777465  1.47645122 1.47134847 1.46673366 1.46291082 1.46040621\n",
      " 1.45778024 1.45504521 1.45066012 1.44988774 1.44506138 1.44328701\n",
      " 1.44197048 1.43132014 1.42986688 1.42791678 1.42402558 1.42209776\n",
      " 1.41770329 1.4142509  1.41077705 1.40954163 1.40815976 1.40411988\n",
      " 1.40004786 1.39939061 1.39482696 1.3932591  1.38685985 1.38540573\n",
      " 1.38263876 1.3791766  1.37666848 1.37119141 1.36974528 1.36779446\n",
      " 1.36452773 1.36316084 1.36157566 1.35656566 1.35573596 1.3508866\n",
      " 1.34951576 1.34901863 1.34343882 1.33968246 1.33730715 1.33510286\n",
      " 1.3323069  1.32790744 1.32669398 1.32209579 1.31896994 1.31757484\n",
      " 1.3141846  1.31301675 1.31113054 1.31031848 1.30461381 1.30268509\n",
      " 1.29693687 1.29421785 1.29172404 1.2892605  1.28735147 1.28363577\n",
      " 1.28183503 1.27866789 1.27639875 1.27354529 1.2697718  1.26807765\n",
      " 1.26305845 1.2600599  1.25792895 1.25268014 1.25062218 1.24781566\n",
      " 1.2433229  1.24276328 1.23676333 1.23563187 1.23137147 1.22987196\n",
      " 1.22384616 1.22163437 1.21992653 1.21577669 1.21208848]\n",
      "(239, 2022)\n"
     ]
    }
   ],
   "source": [
    "#lsa를 쓰면? 잠재 의미 분석을 사용해보도록 하자. \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=239, n_iter=7, random_state=42) #압축할 component의 수 지정\n",
    "svd.fit(X_train_tfidf)  \n",
    "print(svd.explained_variance_ratio_)  #계산된 각 component가 설명하는 분산의 비율\n",
    "print(svd.explained_variance_ratio_.sum())  #선택된 component들이 설명하는 분산의 합 -> 선택한 component의 수에 따라 달라짐\n",
    "print(svd.singular_values_) \n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:18:13.521980Z",
     "start_time": "2020-11-08T09:18:13.411986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.770\n",
      "Test set score: 0.659\n"
     ]
    }
   ],
   "source": [
    "X_train_svd = svd.transform(X_train_tfidf) #선택된 component를 이용하여 2,000개의 feature로부터 feature extract (dimension reduce)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SVD_clf = LogisticRegression()\n",
    "SVD_clf.fit(X_train_svd, y_train)\n",
    "print('Train set score: {:.3f}'.format(SVD_clf.score(X_train_svd, y_train)))\n",
    "print('Test set score: {:.3f}'.format(SVD_clf.score(X_test_svd, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-08T09:18:47.766829Z",
     "start_time": "2020-11-08T09:18:36.148543Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhojonghyun\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:484: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (1370, 1584)\n",
      "Test set dimension: (457, 1584)\n",
      "Train set score: 0.801\n",
      "Test set score: 0.685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer=twit_tokenizer2, min_df=2).fit(X_train) #tfidf와 동일하게 max_feature를 제한하여 학습\n",
    "X_train_cv = cv.transform(X_train) # train set을 변환\n",
    "print('Train set dimension:', X_train_cv.shape) # 36310 대신 2000이 된 것을 확인\n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결론\n",
    "\n",
    "train set과 test set 비중이 둘다 어느수준을 넘어가는 기법을 사용하도록 하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
